---
layout: about
title: about
permalink: /
subtitle: <b>PhD candidate at the University of Edinburgh, Robotics and Autonomous systems CDT</b>


profile:
  align: right
  image: prof_pic.jpg
  image_circular: true # crops the image to make it circular
  more_info: >
    <p>S[DOT]GARCIN[AT]ED.AC.UK</p>

news: true # includes a list of news item
[//]: # (latest_posts: false # includes a list of the latest posts)
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

I am a PhD candidate and a member of the [Autonomous Agents Research Group](https://agents.inf.ed.ac.uk/) at the University of Edinburgh. I am fortunate to be co-advised by [Stefano Albrecht](https://agents.inf.ed.ac.uk/stefano-albrecht/) and [Chris Lucas](https://lucaslab-uoe.github.io/members/chris/). Before starting my PhD I completed an MEng in Aeronautics at Imperial College London, where I started the [Imperial College Aerial Vehicle project](https://icavproject.wordpress.com), and then worked three years in the aerial robotics industry. I have been previously involved in [multi-agent robotic navigation](https://ieeexplore.ieee.org/abstract/document/9143181) and [autonomous](https://github.com/uoe-agents/IGP2) [vehicles](https://ieeexplore.ieee.org/abstract/document/9636279) research projects.

My PhD investigates how to understand the _generalisation capabilities_ of deep reinforcement learning algorithms through the study of the _flow of information_ passing through the model over the course of training. In reinforcement learning, the training data is generated online as the agent interacts with its environment, and we must consider this _data generation process_ when studying this flow. 

When the agent is trained in simulation, this process is not solely determined by the agent policy but also by the environment instance selected in the simulator. I've recently been investigating how novel forms of information bottlenecks may be induced by [adaptively sampling from a set of environment instances or augmenting this set using a generative model](https://arxiv.org/abs/2310.03494). As such, my work has connections to the fields of _generative modeling_, _environment design_ and _autocurricula generation_.

[//]: # (My PhD investigates the _generalisation capabilities_ of reinforcement learning algorithms. Generalisation may be understood as a learning algorithm's ability to optimise an objective while learning a model that is invariant to the composition of the training data. Invariance may be obtained through various regularisation techniques such as data augmentation, noise injection or learning an ensemble of models and, under the lens of information theory, it corresponds to enforcing a bottleneck over the _flow of information_ between the input data and the model's output. My research aims to understand generalisation through the study of this flow, which presents unique challenges and opportunities in the context of reinforcement learning.)

[//]: # ()
[//]: # (While effective information bottlenecks may be induced through the regularisation techniques described above, the information flow is also a function of the training data, which is not fixed in the reinforcement learning setting but is generated online by interaction with the environment. When the agent is trained in a simulator, data generation is not only determined by the agent policy, but also by the environment instance selected by the simulator. An important part of my work consists of studying how novel forms of information bottlenecks may be induced by [adaptively sampling from a set of environment instances or augmenting this set using a generative model]&#40;https://arxiv.org/abs/2310.03494&#41;. As such, my research has connections to the fields of _generative modeling_, _environment design_ and _autocurricula generation_.)

I am _always_ interested in collaboration opportunities so feel free to reach out via email or through any of the channels listed at the bottom of this page! I am currently on the market for research internships. 

I organise our group's virtual [Reinforcement Learning Reading Group](https://agents.inf.ed.ac.uk/reading-group/), do reach out if you would like to come present your work. If you are in Edinburgh, I also organise an in-person discussion group on the topic of generalisation in machine learning.

[//]: # (Finally, the non-stationarity of the training distribution and its interdependence with the learned model challenges the assumptions made in prior work regarding information flow and generalisation, and as such part of this project investigates how to extend existing results to the reinforcement learning setting.)

[//]: # (subtitle: <p style="color:var&#40;--global-theme-color&#41;;">PhD candidate at the University of Edinburgh, Robotics and Autonomous systems CDT</p>)

[//]: # (subtitle: **PhD candidate at the University of Edinburgh, Robotics and Autonomous systems CDT**)
[//]: # (Link to your social media connections, too. This theme is set up to use [Font Awesome icons]&#40;https://fontawesome.com/&#41; and [Academicons]&#40;https://jpswalsh.github.io/academicons/&#41;, like the ones below. Add your Facebook, Twitter, LinkedIn, Google Scholar, or just disable all of them.)